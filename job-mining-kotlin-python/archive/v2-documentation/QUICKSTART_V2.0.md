# ðŸš€ JOB MINING HYBRID APPLICATION V2.0

## âœ… Was neu ist

### Clean Architecture
- **Domain Layer** (core/models_v2.py): Reine Business-Logik, keine Framework-Dependencies
- **Application Layer** (services/): Orchestrierung und GeschÃ¤ftslogik
- **Infrastructure Layer** (repositories/): Datenzugriff und externe APIs

### 7-Ebenen-Modell vollstÃ¤ndig implementiert
1. âœ… Discovery (is_discovery Flag)
2. âœ… Level (1-8 ESCO Level)
3. âœ… Digital Skills (is_digital Flag)
4. âœ… Domain Inference (source_domain, inferred_level)
5. âœ… Fachbuch/Academia Support (inferred_level 4-5)
6. âœ… Segmentierung & Rolle (is_segmented, role_context)
7. âœ… Zeitreihen-Analyse (year, date_parsed, CompetenceTimeSeries)

### Docker-fÃ¤hig
```bash
docker-compose -f docker-compose.v2.yml up
```

### Fuzzy-Matching-Strategie
- `SpacyCompetenceExtractor` mit NLP
- `HybridCompetenceRepository` mit ESCO + Custom Skills
- RapidFuzz fÃ¼r fehlerrobuste Matches

---

## ðŸš€ Quick Start

### 1. Lokale Entwicklung

```bash
# Environment
python -m venv venv
source venv/bin/activate  # oder: venv\Scripts\activate auf Windows
pip install -r requirements.txt

# NLP-Modell herunterladen
python -m spacy download de_core_news_sm

# Run V2.0
python main_v2.py
```

**Erwartet Output:**
```
================================================================================
ðŸš€ JOB MINING HYBRID APPLICATION V2.0
================================================================================

ðŸ“¦ Initialisiere Repositories...
ðŸ§  Starte spaCy NLP Extractor...

ðŸ“Š VERFÃœGBARE DATENQUELLEN:
   - ESCO Skills geladen: 31655
   - Custom Skills geladen: 245
   - Digitale Skills: 1537

ðŸ” Extrahiere Kompetenzen aus Testdokument...

âœ… 8 Kompetenzen erkannt:
   - Python (Vertrauen: 95%)
   - Django (Vertrauen: 92%)
   - REST APIs (Vertrauen: 88%)
   ...

ðŸ’¾ Erstelle JobPosting-EntitÃ¤t...

âœ¨ JobPosting erstellt:
   Titel: Senior Python Developer
   Ort: Berlin
   Jahr: 2025
   Kompetenzen: 8

================================================================================
âœ… V2.0 PIPELINE ERFOLGREICH!
================================================================================
```

### 2. Docker

```bash
# Build & Run
docker-compose -f docker-compose.v2.yml up --build

# PrÃ¼fe Logs
docker-compose -f docker-compose.v2.yml logs python-backend
```

---

## ðŸ“Š Datenmodell

### Competence (Immutable)
```python
@dataclass(frozen=True)
class Competence:
    name: str                           # "Python"
    esco_uri: Optional[str]             # "ESCO:123"
    category: Optional[str]             # "Programming Language"
    domain: Optional[str]               # "ICT"
    competence_type: CompetenceType     # SKILL
    confidence: float                   # 0.95
    source_match: Optional[str]         # "python programming"
    source_section: Optional[str]       # "requirements"
    level: Optional[int]                # 3
    is_digital: bool                    # True
    role_context: Optional[str]         # "IT & Softwareentwicklung"
```

### JobPosting
```python
@dataclass
class JobPosting:
    job_id: str                         # "job_123"
    source_path: str                    # "/data/jobs/123.docx"
    raw_text: str                       # Volltext
    title: str                          # "Senior Python Developer"
    company: str                        # "TechCorp"
    location: str                       # "Berlin"
    year: int                           # 2025 (KRITISCH fÃ¼r Zeitreihen)
    date_parsed: date                   # 2025-01-15
    is_segmented: bool                  # True wenn Tasks/Reqs extrahiert
    tasks_text: str                     # Extrahierte Aufgaben
    requirements_text: str              # Extrahierte Anforderungen
    competences: List[Competence]       # Gefundene Kompetenzen
    extraction_quality_score: float     # 0.88 (QualitÃ¤t der Extraktion)
    # ... weitere Felder
```

---

## ðŸ”„ Pipeline-Flow

```
1. DocumentLoader
   â””â”€> raw_text (PDF/DOCX)

2. MetadataExtractor
   â””â”€> title, company, location, year, role

3. TextSegmenter
   â””â”€> tasks_text, requirements_text

4. SpacyCompetenceExtractor (mit HybridCompetenceRepository)
   â””â”€> competences: List[Competence]

5. JobPosting-EntitÃ¤t (mit allen Metadaten)
   â””â”€> gespeichert/serialisiert
```

---

## ðŸ“ˆ Zeitreihen-Analyse (Masterprojekt)

```python
# Alle Jobs gruppiert nach Jahr und Kompetenz
competence_ts = CompetenceTimeSeries(competence)
for job in jobs:
    if job.year:
        competence_ts.add_occurrence(job.year)

# Trend ermitteln
trend = competence_ts.trend()  # 'rising', 'falling', 'stable'
```

---

## âœ¨ NÃ¤chste Schritte

- [ ] REST API (FastAPI) fÃ¼r Job-Analyse hinzufÃ¼gen
- [ ] Dashboard mit Trendanalyse
- [ ] Kotlin API Integration
- [ ] Unit Tests & E2E Tests
- [ ] Mehrsprachige Datenquellen (EN, FR, etc.)

---

## ðŸ†˜ Troubleshooting

### spaCy Modell nicht gefunden
```bash
python -m spacy download de_core_news_sm
```

### ESCO-Daten nicht geladen
- PrÃ¼fe: `python-backend/data/esco/*.csv` existiert
- CSV-Format muss passen (;-separiert)

### Docker-Build schlÃ¤gt fehl
```bash
docker system prune  # cleanup
docker-compose -f docker-compose.v2.yml build --no-cache
```

---

**Status:** âœ… Production-Ready V2.0
**Last Updated:** 2025-12-27
